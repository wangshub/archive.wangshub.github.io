<!DOCTYPE html>
<html lang="zh-cn">
    <head>
    <meta http-equiv="content-type" content="text/html;charset=utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noodp"/>
    <meta name="author" content="神奇的战士">
    
    <meta name="keywords" content="blog, GNU/Linux, Linux, Ubuntu, Docker, Robot, Python, DRL">
    
    <link rel="prev" href="https://wangshub.github.io/posts/pybulet-gym%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%8F%8C%E8%B6%B3%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%A8%A1%E5%9E%8Bhumanoidpybulletenv-v0/" />
    <link rel="next" href="https://wangshub.github.io/posts/%E5%8F%8C%E8%B6%B3%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%A6%82%E4%BD%95%E8%A1%8C%E8%B5%B0/" />
    <link rel="canonical" href="https://wangshub.github.io/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%BD%B1%E5%93%8D/" />
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>
        
        
            强化学习策略网络复杂度的影响 | 🍉 神奇的战士
        
    </title>
    <meta name="title" content="强化学习策略网络复杂度的影响 | 🍉 神奇的战士">
    
<link rel="stylesheet" href="/css/main.min.css">


    
    
 

<script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https:\/\/wangshub.github.io"
    },
    "articleSection" : "posts",
    "name" : "强化学习策略网络复杂度的影响",
    "headline" : "强化学习策略网络复杂度的影响",
    "description" : "强化学习策略网络调参 传统的基于状态-动作强化学习方法会遇到维度诅咒的问题，为了解决这个问题，基于策略的强化学习方法被提出，比如经典的策略梯度",
    "inLanguage" : "zh-cn",
    "author" : "神奇的战士",
    "creator" : "神奇的战士",
    "publisher": "神奇的战士",
    "accountablePerson" : "神奇的战士",
    "copyrightHolder" : "神奇的战士",
    "copyrightYear" : "2019",
    "datePublished": "2019-11-04 17:20:29 \u002b0000 UTC",
    "dateModified" : "2019-11-04 17:20:29 \u002b0000 UTC",
    "url" : "https:\/\/wangshub.github.io\/posts\/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%BD%B1%E5%93%8D\/",
    "wordCount" : "790",
    "keywords" : [ "ReinfocementLearning","Algorithm", "🍉 神奇的战士"]
}
</script>

  </head>
    <body class="">
        <div class="wrapper">
            <nav class="navbar">
    
        <progress class="content_progress" max="0" value="0"></progress>
    
    <div class="container">
        
            <div class="navbar-header header-back2home-logo">
                <span class="logo_mark" >>$</span>
                <a href="https://wangshub.github.io">
                    <span class="logo_text" >cd /home/</span>
                    <span class="logo_cursor" ></span>
                </a>
            </div>
        
        <div class="navbar-right">
                
                <span class="menu">
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
                <a class="menu-item" href="/tags/" title="">Tags</a>
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <span class="divide"></span>
                <a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a>
                </span>
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
    
        <progress class="content_progress" max="0" value="0"></progress>
    
     <div class="container">
        <div class="navbar">
            <div class="navbar-header header-logo">
                    <a href="https://wangshub.github.io">🍉 神奇的战士</a>
            </div>
            <div class="navbar-right">
                <div><a href="javascript:void(0);" class="theme-switch"><i class="iconfont icon-dark-mode"></i></a></div>
                <div class="menu-toggle">
                    <span></span><span></span><span></span>
                </div>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                <nav class="mb-md">
                    
                    
                        <a class="menu-item" href="/posts/" title="">
                            <h3>Blog</h3>
                            <div class="menu-active"></div>
                        </a>
                    
                        <a class="menu-item" href="/tags/" title="">
                            <h3>Tags</h3>
                            <div class="menu-active"></div>
                        </a>
                    
                        <a class="menu-item" href="/about/" title="">
                            <h3>About</h3>
                            <div class="menu-active"></div>
                        </a>
                    
                </nav>
        </div>
    </div>
</nav>
            <main class="main">
                <div class="container">
                    
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">强化学习策略网络复杂度的影响</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="https://wangshub.github.io" rel="author">神奇的战士</a> with ♥
                <span class="post-time">
                on <time datetime=2019-11-04 itemprop="datePublished">November 4, 2019</time>
                </span>
                in
                
                <span class="post-word-count">790 words</span>
        </div>
    </header>

    <div class="post-content">
        

        
        

        
        
        
        
        

        
        
        

        <h1 id="强化学习策略网络调参">强化学习策略网络调参</h1>
<p>传统的基于<strong>状态-动作</strong>强化学习方法会遇到<strong>维度诅咒</strong>的问题，为了解决这个问题，基于策略的强化学习方法被提出，比如经典的策略梯度方法，使用神经网络，可以用于表示高纬度的<strong>状态-&gt;动作</strong>空间的映射关系。这样可以把维度降低，实现更快的收敛。</p>
<p>为了找到最优解，策略的参数数量必须要足够多，以至于能够合理的表示策略空间。在策略梯度中，策略网络常常用一个 MLP 网络表示策略参数 $\theta$。</p>
<p><strong>那么是否参数越多越好</strong>？答案是否定的。</p>
<ul>
<li>参数较少时，收敛速度快，容易找到次优解；</li>
<li>参数过多时，收敛速度慢，容易陷入局部最优；</li>
</ul>
<p>所以需要合理设置策略参数个数，评估网络的复杂度，在强化学习任务中是非常困难的，常常需要大量实验试错调节参数。但是在许多论文中，没有提及这部分工作，只是说道根据<strong>经验值</strong>&hellip;相似的超参数还有</p>
<ul>
<li>奖励函数</li>
<li>衰减系数</li>
<li>Exploration Noise</li>
<li>&hellip;</li>
</ul>
<p>上面这些超参数，调整一个，就需要从头开始训练，过去所有收集到的数据都需要扔掉，这个过程采样效率低，耗时长，如下图所示，使策略收敛，训练一个 Agent 经常需要上百万次的采样，故不能直接在实体机器人上训练策略。</p>
<div style="text-align:center"><img src ="https://raw.githubusercontent.com/wangshub/image-hosting/master/img/20191104171929.png" width="60%" /></div>
<p><strong>So &hellip; 怎么调参？</strong></p>
<p><a href="https://spinningup.openai.com/en/latest/spinningup/spinningup.html#learn-by-doing">《Spinning Up》</a> 中提出了一些建议，或许有用</p>
<ul>
<li>从论文中查找细节参数，比如网络的结构、奖励函数和超参数设置等等，但是注意不要陷入到论文中。</li>
<li>在简单的强化学习环境中快速试验算法，首先要验证算法的正确性，保证在像 CartPole-v0、InvertedPendulum-v0、 FrozenLake-v0 和 HalfCheetah-v2 简单的环境中，算法可以收敛。这样只需要花几分钟就可以验证想法，而不等好几天！然后再将算法应用到像雅达利游戏和机器人这样复杂的环境中。</li>
<li>如果在一个环境中调节超参数，始终达不到满意效果，这可能是一个 Bug，试着在别的强化学习环境中验证；</li>
<li>测量尽可能多的结果，比如均值/方差/最小值/最大值，观察 Agent 在环境中的行为，这可能会提供一些思路；</li>
</ul>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://spinningup.openai.com/en/latest/spinningup/spinningup.html#learn-by-doing">Spinning Up as a Deep RL Researcher</a></li>
<li><a href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html">Policy Gradient Algorithms</a></li>
<li><a href="http://karpathy.github.io/2016/05/31/rl/">Deep Reinforcement Learning: Pong from Pixels</a></li>
</ul>

    </div>

    <div class="post-copyright">
            
            <p class="copyright-item">
                <span>Author:</span>
                <span>神奇的战士 </span>
                </p>
            

            
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=https://wangshub.github.io/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%BD%B1%E5%93%8D/>https://wangshub.github.io/posts/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%E7%BD%91%E7%BB%9C%E7%9A%84%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%BD%B1%E5%93%8D/</span>
            </p>
            
            
            <p class="copyright-item lincese">
                本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
            </p>
            
    </div>


    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s):
            
            <span class="tag"><a href="https://wangshub.github.io/tags/reinfocementlearning/">
                    #ReinfocementLearning</a></span>
            
            <span class="tag"><a href="https://wangshub.github.io/tags/algorithm/">
                    #Algorithm</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> ·
                <span><a href="https://wangshub.github.io">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="https://wangshub.github.io/posts/pybulet-gym%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E5%8F%8C%E8%B6%B3%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%A8%A1%E5%9E%8Bhumanoidpybulletenv-v0/" class="prev" rel="prev" title="Pybulet Gym 源码解析：双足机器人模型 HumanoidPyBulletEnv-v0"><i class="iconfont icon-left"></i>&nbsp;Pybulet Gym 源码解析：双足机器人模型 HumanoidPyBulletEnv-v0</a>
        
        
        <a href="https://wangshub.github.io/posts/%E5%8F%8C%E8%B6%B3%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%A6%82%E4%BD%95%E8%A1%8C%E8%B5%B0/" class="next" rel="next" title="双足机器人如何行走？">双足机器人如何行走？&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
        
            
        
    </div>
</article>
                </div>
            </main>
            <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2016 - 2021</span>
        
        <span class="with-love">
    	 <i class="iconfont icon-love"></i>
         </span>
         
            <span class="author" itemprop="copyrightHolder"><a href="https://wangshub.github.io">神奇的战士</a> | </span>
         

         
		  <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/Mogeko/Mogege" target="_blank" rel="external nofollow">Mogege</a></span>
    </div>
</footer>






<script defer src="/js/vendor_main.min.js"></script>







<script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script> pangu.spacingPage();</script>



<script>
  MathJax = {
    tex: {
      inlineMath: [["$", "$"]],
    },
    displayMath: [
      ["$$", "$$"],
      ["\[\[", "\]\]"],
    ],
    svg: {
      fontCache: "global",
    },
  };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>

        </div>
    </body>
</html>
