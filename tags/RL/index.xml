<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RL on 🍉 神奇的战士</title><link>https://wangshub.github.io/tags/rl/</link><description>Recent content in RL on 🍉 神奇的战士</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Mon, 11 Mar 2019 20:27:30 +0000</lastBuildDate><atom:link href="https://wangshub.github.io/tags/rl/index.xml" rel="self" type="application/rss+xml"/><item><title>强化学习之 Deep Q­-Learning</title><link>https://wangshub.github.io/posts/rldeepqlearning/</link><pubDate>Mon, 11 Mar 2019 20:27:30 +0000</pubDate><guid>https://wangshub.github.io/posts/rldeepqlearning/</guid><description>Deep Q­-Learning Q-Learning 在 Q-Learning 中定义函数 $Q(s, a)$ 表示在当前状态 $s$ 下采取动作 $a$ 获得的最大有损奖励 $$ Q\left(s_{t}, a_{t}\right)=\max R_{t+1} $$ 可以将 $Q(s, a)$ 理解为在一局游戏中，如果在状态</description></item></channel></rss>